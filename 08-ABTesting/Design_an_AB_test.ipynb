{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design an A/B Test\n",
    "\n",
    "[Cédric Campguilhem](https://github.com/ccampguilhem/Udacity-DataAnalyst), March 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Top\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Experiment design](#Design)\n",
    "    - [Metric choice](#Metric)\n",
    "    - [Measuring standard deviation](#Standard deviation)\n",
    "    - [Sizing](#Sizing)\n",
    "- [Experiment analysis](#Analysis)\n",
    "    - [Sanity checks](#Sanity)\n",
    "    - [Result analysis](#Result)\n",
    "    - [Recommendations](#Recommendations)\n",
    "- [Follow-up experiment](#Followup)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Introduction\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction [*top*](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is related to A/B testing course for Udacity Data Analyst Nanodegree program. The purpose of this project is to analyse an experiment made at Udacity.\n",
    "\n",
    "The experiment is related to a change when student clicks \"start free trial\" button. A message asks them how much time they would dedicate to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead.\n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time—without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Design\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment design [*top*](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Metric\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric choice [*Experiment design*](#Design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters have been selected as invariants of the analysis (i.e. parameters which should not be affected by the change being analyzed). All those metrics are captured upstream to the change being analyzed.\n",
    "\n",
    "Invariant                    | Description                      \n",
    ":----------------------------|:---------------------------------\n",
    "Number of cookies            | Number of unique cookies to view the course overview page. \n",
    "Number of clicks             | Number of unique cookies to click on \"Start free trial\" button \n",
    "Click-through-probability    | Number of unique cookies to click on \"Start free trial\" button divided by the number of unique cookies to view the course page overview.\n",
    "\n",
    "All other metrics (Number of user-ids, Gross conversion, Retention, Net conversion) are collected downstream to change and may potentially being affected by change.\n",
    "\n",
    "The following parameters have been selected as evaluation metrics because it collects information downstream to change and are related to the objectives of this A/B test which are: \n",
    "\n",
    "- minimizing the proportion of enrolled students quiting during the trial\n",
    "- keeping the same proportion of students clicking the start free trial and continuing the course afterwards\n",
    "\n",
    "Evaluation metrics  | Description | Practical significance boundary | Reasons of choice\n",
    ":-------------------|:------------|:--------------------------------|:------------------\n",
    "Gross conversion    | Number of user-ids to enroll in the free trial divided by the number of unique cookies to click on the \"Start free trial\" button. | ${d}_{min} = 0.01$ | This captures the proportion of students changing their mind after the time commitment warning.\n",
    "Retention           | Number of user-ids to remain enrolled after the trial divided by the number of user-ids enrolled during the trial. | ${d}_{min} = 0.01$ | This metric enables to evaluate first objective: minimize number of students quitting during the trial.\n",
    "Net conversion      | Number of user-ids to remain enrolled after the trial divided by the number of unique cookies to click the \"Start free trial\" button. | ${d}_{min} = 0.0075$ | This metrics enables to evaluate the second objective: keep the same proportion of students enrolled in the long term.\n",
    "\n",
    "Number of user-ids who enroll in the free trial may be affected by change but does not provide any relevant information serving the objective of the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Standard deviation\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring standard error [*Experiment design*](#Design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error for each evaluation metrics will be calculated with the following data:\n",
    "\n",
    "Parameter | Value\n",
    ":---------|:------\n",
    "Unique cookies to view course overview page per day |\t40000\n",
    "Unique cookies to click \"Start free trial\" per day | 3200\n",
    "Enrollments per day |\t660\n",
    "Click-through-probability on \"Start free trial\" |\t0.08\n",
    "Probability of enrolling, given click |\t0.20625\n",
    "Probability of payment, given enroll |\t0.53\n",
    "Probability of payment, given click\t| 0.1093125\n",
    "\n",
    "The *probability of enrolling, given click* is linked to the *gross conversion* metric. *Probability of payment, given enroll* is in relation with the *retention* metric. Finally, *probability of payment, given click* is related to *net conversion* metric. As we are dealing with probabilities, we will assume to have a binomial distribution. We can then estimate the standard error for each metric using the binomial standard deviation:\n",
    "\n",
    "\\begin{align}\n",
    "SE = \\sqrt{\\frac{p(1-p)}{n}}\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "- p is the probability of event\n",
    "- n is the number of repetitions of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400.0 82.5\n"
     ]
    }
   ],
   "source": [
    "nb_cookies = 5000.\n",
    "nb_clicks = nb_cookies * 3200. / 40000.\n",
    "nb_enrollments = nb_clicks * 660. / 3200.\n",
    "print nb_clicks, nb_enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020230604137 0.0549490121785 0.0156015445825\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "stddev_gross = math.sqrt(0.20625 * (1 - 0.20625) / nb_clicks)\n",
    "stddev_retention = math.sqrt(0.53 * (1 - 0.53) / nb_enrollments)\n",
    "stddev_conversion = math.sqrt(0.1093125 * (1 - 0.1093125) / nb_clicks)\n",
    "print stddev_gross, stddev_retention, stddev_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample size is 5000 cookies. We can then assume that we will have 400 clicks on the \"Start free trial button\" and 82.5 enrollments. The standard deviations are reported in the table below:\n",
    "\n",
    "Evaluation metrics | Units of analysis (n) | Estimated standard deviation\n",
    ":------------------|:----------------------|:----------------------------\n",
    "Gross conversion   | cookie (400)          | 0.0202\n",
    "Retention          | user-id (82)          | 0.0549\n",
    "Net conversion     | cookie (400)          | 0.0156\n",
    "\n",
    "Gross conversion and net conversion use cookie as unit of analysis and unit of diversion, so the analytical standard error calculated here shall be quite close from empirical values. This is not the case for retention metrics as it uses user-id and we could have differences between empirical variability and the one estimated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sizing\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing [*Experiment design*](#Design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of samples vs power\n",
    "\n",
    "Assuming that all metrics are independent, the probability of having at least one false positive would be $1 - (0.95 * 0.95 * 0.95) = 0.14$. Using the Bonferroni correction is a way to reduce the overall chance to get false positive by increasing significance level (reducing alpha value) for each test that is made. However, I am not going to use it. Using it significantly increases the duration of the experiment and assumes that tests are independent. Besides, we will see later that one evaluation metric is going to be discarded, letting us with only two metrics. In this configuration there is 9,8% of chance of having a false positive.\n",
    "\n",
    "I have used the online calculator provide by [Evan Miller](http://www.evanmiller.org/ab-testing/sample-size.html) to estimate sample size for A/B test. The results are provided in the table below:\n",
    "\n",
    "Parameter            | Base conversion rate | Practical significance | $\\alpha$ | $1 - \\beta$ | Sample size per variation\n",
    ":--------------------|:---------------------|:-----------------------|:---------|:------------|:-------------------------\n",
    "Gross conversion     | 20.625 %             | 1.0 %                  | 5.0 %    | 80.0 %      | 25835\n",
    "Retention            | 53.0 %               | 1.0 %                  | 5.0 %    | 80.0 %      | 39115\n",
    "Net conversion       | 10.93125 %           | 0.75 %                 | 5.0 %    | 80.0 %      | 27413\n",
    "\n",
    "The retention metrics is the one requiring the most samples per variation. But as this metrics is also using user-id as units of analysis, it also need to be converted to clicks, increasing again the number of page views (only 8% of view lead to clicks):\n",
    "\n",
    "\\begin{equation}\n",
    "{pageviews} = \\frac{39115 * 2}{0.08 * 0.20625}\n",
    "\\end{equation}\n",
    "\n",
    "The equation above assumes that both control and test groups are seeing the same number of pages and leads to 4741212 page views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0975\n",
      "4741212.12121\n"
     ]
    }
   ],
   "source": [
    "print 1 - (0.95 * 0.95)\n",
    "print 39115. / (0.08 * 0.20625) * 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration vs exposure\n",
    "\n",
    "We have 40000 unique cookies to view course overview per day. If we redirect half of the traffic, the duration would be:\n",
    "\n",
    "\\begin{equation}\n",
    "duration = \\frac{4741212}{40000 * 0.5}\n",
    "\\end{equation}\n",
    "\n",
    "The equation above leads to 238 days ! That's a long experiment and Udacity does not want to spend that long. We need to rework some of the previous decisions we have made.\n",
    "\n",
    "The retention metric is really demanding in terms of page views. If we drop this metric, the dimensionning metric is net conversion which now requires 685325 page views. If we increase the redirection factor to two-third of the traffic, this lead to a duration of 26 days which is much more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.0606\n"
     ]
    }
   ],
   "source": [
    "print 4741212 / (40000 * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685325.0\n",
      "25.959280303\n"
     ]
    }
   ],
   "source": [
    "print 27413 / 0.08 * 2.\n",
    "print 685325.0 / (40000 * 0.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This desing exposes one third of students to a new feature during less than one month. The nature of feature is to minimize students starting the free trial without willing to dedicate more than 5 hours a week to follow the course. This feature shall not change the mind of students wanting to take the course and agreeing to dedicate a long time to it. So running this test is probably an acceptable risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Analysis\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment analysis [*top*](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sanity\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks [*Experiment analysis*](#Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a alpha of 0.05, the critical $z^*$ value for a two tailed test is 1.96.\n",
    "\n",
    "The total number of cookies in each group is:\n",
    "\n",
    "- experiment group: $n_1$\n",
    "- control group: $n_2$\n",
    "- probability to be in experiment group (by design): $p=0.5$\n",
    "- observed probability to be in experiment group: ${p}_{obs}=\\frac{n_2}{n_1+n_2}$\n",
    "\n",
    "\n",
    "The pooled standard error is:\n",
    "\n",
    "\\begin{equation}\n",
    "SE = \\sqrt{\\frac{p(1-p)}{n_1+n_2}}\n",
    "\\end{equation}\n",
    "\n",
    "The margin of error is:\n",
    "\n",
    "\\begin{equation}\n",
    "margin = SE . z^*\n",
    "\\end{equation}\n",
    "\n",
    "The confidence interval is:\n",
    "\n",
    "\\begin{equation}\n",
    "CI = [0.5 - margin, 0.5 + margin]\n",
    "\\end{equation}\n",
    "\n",
    "The sanity check is passed if observed probability $p_{obs}$ is within confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95996398454 0.000601840740294 (0.49882041382459419, 0.50117958617540581) 0.500639666881 True\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "#Probability\n",
    "alpha = 0.05\n",
    "z_star = -scipy.stats.norm.ppf(alpha / 2.) #two-tailed tests\n",
    "n1 = 344660.\n",
    "n2 = 345543.\n",
    "p = 0.5\n",
    "p_obs = n2 / (n1 + n2)\n",
    "\n",
    "#Pooled Standard error\n",
    "SE = math.sqrt(p * (1 - p) / (n1 + n2))\n",
    "\n",
    "#Confidence interval\n",
    "me = SE * z_star\n",
    "ci = p - me, p + me\n",
    "\n",
    "#Measure\n",
    "print z_star, SE, ci, p_obs, ci[0] <= p_obs <= ci[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For number of cookies:\n",
    "- confidence interval: [0.4988, 0.5012]\n",
    "- observed probability: 0.4994\n",
    "- sanity check: **passed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95996398454 0.0020997470797 (0.49588457134714631, 0.50411542865285364) 0.500467347407 True\n"
     ]
    }
   ],
   "source": [
    "#Probability\n",
    "alpha = 0.05\n",
    "z_star = -scipy.stats.norm.ppf(alpha / 2.) #two-tailed test\n",
    "n1 = 28325.\n",
    "n2 = 28378.\n",
    "p = 0.5\n",
    "p_obs = n2 / (n1 + n2)\n",
    "\n",
    "#Pooled Standard error\n",
    "SE = math.sqrt(p * (1 - p) / (n1 + n2))\n",
    "\n",
    "#Confidence interval\n",
    "me = SE * z_star\n",
    "ci = p - me, p + me\n",
    "\n",
    "#Measure\n",
    "print z_star, SE, ci, p_obs, ci[0] <= p_obs <= ci[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For number of clicks:\n",
    "- confidence interval: [0.4959, 0.5041]\n",
    "- observed probability: 0.5005\n",
    "- sanity check: **passed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95996398454 0.000467068276555 (0.081210376574208529, 0.083041250574945116) 0.0821258135746 0.0821824406662 True\n"
     ]
    }
   ],
   "source": [
    "#Probability\n",
    "alpha = 0.05\n",
    "z_star = -scipy.stats.norm.ppf(alpha / 2.) #two-tailed test\n",
    "n1 = 344660.\n",
    "c1 = 28325.\n",
    "n2 = 345543.\n",
    "c2 = 28378.\n",
    "p = c2 / n2\n",
    "p_obs = c1 / n1\n",
    "\n",
    "#Standard error\n",
    "SE = math.sqrt(p * (1 - p) / n2)\n",
    "\n",
    "#Confidence interval\n",
    "me = SE * z_star\n",
    "ci = p - me, p + me\n",
    "\n",
    "#Measure\n",
    "print z_star, SE, ci, p, p_obs, ci[0] <= p_obs <= ci[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the click-through-probability we use a slightly different approach. The average click-through-probability is 0.0821 based on control group. We are no longer using a pooled standard error. We then need to check that click-through-probability for experiment group lies within the confidence interval:\n",
    "\n",
    "- confidence interval: [0.0812, 0.0830]\n",
    "- observed probability: 0.0822\n",
    "- sanity check: **passed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Result\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result analysis [*Experiment analysis*](#Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect size tests\n",
    "\n",
    "The dataset records 23 days of experiment in terms of unique cookies, clicks, enrollments and payments. This duration is lower than the duration we have designed. All other things being equal, this means that we are losing statistical power $1 - \\beta$ (percent of the time the minimum effect size will be detected, assuming it exists). A reduction of samples is related to an increase of $\\beta$.\n",
    "\n",
    "That being said, we can calculate confidence interval and state whether each evaulation metric is statistically significant and practically significant).\n",
    "\n",
    "The method used to calculate confidence interval changes:\n",
    "\n",
    "\\begin{equation}\n",
    "p = \\frac{events_{control} + events_{experiment}}{clicks_{control} + clicks_{experiment}} \\\\\n",
    "SE = \\sqrt{p(1-p)*\\Bigl(\\frac{1}{clicks_{control}}+\\frac{1}{clicks_{experiment}}\\Bigr)} \\\\\n",
    "margin = SE * z^* \\\\\n",
    "d = \\frac{events_{control}}{clicks_{control}} - \\frac{events_{experiment}}{clicks_{experiment}} \\\\\n",
    "CI = [d - margin, d + margin]\n",
    "\\end{equation}\n",
    "\n",
    "The $z^*$ value is calculated from alpha assuming a two-tailed test:\n",
    "\n",
    "\\begin{equation}\n",
    "z^* = 1.96\n",
    "\\end{equation}\n",
    "\n",
    "A metric is statistically significant if 0 is not included in the confidence interval (there is high chance that there is a difference between experiment and control). Additionaly, it becomes practically significant if the practical difference $d_{min}$ is not in the confidence interval: there is high chance that business sees a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95996398454\n"
     ]
    }
   ],
   "source": [
    "z_star = -scipy.stats.norm.ppf(0.05 / 2.) #two-tailed test + Bonferroni correction\n",
    "#z_star = -scipy.stats.norm.ppf(0.025 / 2.) #two-tailed test + Bonferroni correction\n",
    "print z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208607067404 0.00437167538523 0.00856832630714 -0.0205548745804 (-0.029123200887504669, -0.011986548273218461) True True\n"
     ]
    }
   ],
   "source": [
    "#Gross conversion\n",
    "events_control = 3785\n",
    "clicks_control = 17293.\n",
    "events_experiment = 3423\n",
    "clicks_experiment = 17260.\n",
    "d_min = 0.01\n",
    "p = (events_control + events_experiment) / (clicks_control + clicks_experiment)\n",
    "SE = math.sqrt(p*(1-p)*(1./clicks_control + 1./clicks_experiment))\n",
    "margin = SE * z_star\n",
    "d = events_experiment / clicks_experiment - events_control / clicks_control\n",
    "CI = d - margin, d + margin\n",
    "print p, SE, margin, d, CI, not(CI[0] <= 0. <= CI[1]), not(CI[0] <= d_practical <= CI[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115127485312 0.00343413351293 0.00673077800345 -0.00487372267454 (-0.011604500677993734, 0.0018570553289054001) False True\n"
     ]
    }
   ],
   "source": [
    "#Net conversion\n",
    "events_control = 2033\n",
    "clicks_control = 17293.\n",
    "events_experiment = 1945\n",
    "clicks_experiment = 17260.\n",
    "d_min = 0.0075\n",
    "p = (events_control + events_experiment) / (clicks_control + clicks_experiment)\n",
    "SE = math.sqrt(p*(1-p)*(1./clicks_control + 1./clicks_experiment))\n",
    "margin = SE * z_star\n",
    "d = events_experiment / clicks_experiment - events_control / clicks_control\n",
    "CI = d - margin, d + margin\n",
    "print p, SE, margin, d, CI, not(CI[0] <= 0. <= CI[1]), not(CI[0] <= d_practical <= CI[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are reported in the table below:\n",
    "\n",
    "Evaluation metric | Lower bound | Upper bound | Statistical significance | Practical significance\n",
    ":-----------------|:------------|:------------|:-------------------------|:----------------------\n",
    "gross conversion  | -0.0291     | -0.0120     | Yes                      | Yes\n",
    "net conversion    | -0.0116     |  0.0019     | No                       | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sign tests\n",
    "\n",
    "We have records of 23 days of experiment. The number of enrollments is higher in the experiment group in 4 days (in a row). The number of payments is higher in the experiment group in 10 different days.\n",
    "\n",
    "With the use of [GraphPad](https://www.graphpad.com/quickcalcs/binomial1.cfm), setting the number of \"successes\" to 4 and 10 respectively and a probability of 0.5 we get the following numbers:\n",
    "\n",
    "Gross conversion:\n",
    "- Number of successes: 4\n",
    "- Probability: 0.5\n",
    "- Two-tail p-value: 0.0026\n",
    "- Alpha value: 0.025 (0.05 divided by 2 for a two-tailes test)\n",
    "- The result is statistically significant.\n",
    "\n",
    "Net conversion:\n",
    "- Number of successes: 10\n",
    "- Probability: 0.5\n",
    "- Two-tail p-value: 0.6776 \n",
    "- Alpha value: 0.025 (0.05 divided by 2 for a two-tailes test)\n",
    "- The result is statistically unsignificant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Recommendations\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations [*Experiment analysis*](#Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't use the Bonferroni correction for reasons already discussed in section [Number of samples vs power](#Design). \n",
    "The problem we have here is that the number of samples we have analyzed (23) is below the size we have designed (26). This means that the results we have exposed have a statistical power below 80% (the target was to have a beta value of 0.2). To reach the exepected statistical power the experiment shall be extended.\n",
    "\n",
    "The experiments shows that the impact on gross conversion is both statistically and practically significant. The change in net conversion is unsignificant.\n",
    "\n",
    "The initial objective of the change is:\n",
    "\n",
    "- minimizing the proportion of enrolled students quiting during the trial (retention)\n",
    "- keeping the same proportion of students clicking the start free trial and continuing the course afterwards (net conversion)\n",
    "\n",
    "As there is no statistical difference in terms of net conversion, making the change would not be a high risky for Udacity in terms of revenues. The retention metrics has not been kept in the analysis and it was the better metrics to assess the decrease of proportion of enrolled students quiting during the trial. Howerver, even if less accurate (uses cookies as mean of diversion instead of user-id) the gross conversion has been reduced by the change. We could make a reasonable assumption that both are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Followup\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-up experiment [*top*](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really wanted to follow the course, to me quitting before the end of free trial was not an option. I already knew that I had to dedicate time to the course, my feeling is that you cannot learn something if you are not willing to spend some time with it !\n",
    "\n",
    "However, as a French, I must say that the way the Udacity courses work is pretty different than my experience with French colleges, universities and so on. And I would have advised any of my colleagues interested in the course to have a taste of that way before taking commitment. The balance between theory and practical examples is completly in opposition. Udacity course offers much more practical examples than theory. I like it, but it's pretty different to what I had experienced so far.\n",
    "\n",
    "I am not sure how other countries balance theory and practice in their education. But different cultures may lead to different kind of frustrations.\n",
    "\n",
    "One experiment idea would be to suggest a specific lesson explaining educational choices made by Udacity to give a taste to students before enrollment. The idea would be similar to the experiment conducted here: reduce frustrations of students in the free trial period while focusing Udacity coaches on long-term enrolled students without decreasing significantly long-term enrollments. The specific lesson may not have any coaching at all and students willing to start a new course would be redirected to such lesson first (whatever the course they have chosen).\n",
    "\n",
    "Due to the very close nature of the experiment with the one we have conducted here, I would make almost the same design choices:\n",
    "\n",
    "- Evaluation metrics: net conversion, gross conversion, retention.\n",
    "- Invariants: number of unique cookies, number of clicks on \"start free trial\" button, click-through-probability for \"start free trial button\".\n",
    "\n",
    "However, I would probably increase the practical significance level on gross conversion metric due to the fact that preparing such a dedicated lesson would require more work for Udacity than a simple warning message if the solution is retained (for example adding new feedbacks from former students).\n",
    "\n",
    "I would keep the same unit of diversion (cookies) as this specific lesson would not require user checkout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Appendix\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix [*top*](#Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": [
     "hide_export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Design_an_AB_test.ipynb to html\n",
      "[NbConvertApp] Writing 281308 bytes to Design_an_AB_test.html\n"
     ]
    }
   ],
   "source": [
    "#Convert notebook to html\n",
    "!jupyter nbconvert --to html --template html_minimal.tpl Design_an_AB_test.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Evan Miller](http://www.evanmiller.org/ab-testing/sample-size.html) online calculator for A/B tests sizing.<hr>\n",
    "\n",
    "[Discussion](https://www.widerfunnel.com/3-mistakes-invalidate-ab-test-results/) on whether or not to use Bonferroni correction.<hr>\n",
    "\n",
    "[Bonferroni](https://en.wikipedia.org/wiki/Bonferroni_correction) correction on Wikipedia.<hr>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
