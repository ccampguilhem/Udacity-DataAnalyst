{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap data\n",
    "[Cédric Campguilhem](https://github.com/ccampguilhem/Udacity-DataAnalyst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Top\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [Introduction](#Introduction)\n",
    "- [Map area selection](#Area selection)\n",
    "- [XML data structure](#XML data structure)\n",
    "- [Data quality audit](#Data quality)\n",
    "    - [Validity](#Data validity)\n",
    "    - [Accuracy](#Data accuracy)\n",
    "    - [Completeness](#Data completeness)\n",
    "    - [Consistency](#Data consistency)\n",
    "    - [Uniformity](#Data uniformity)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Introduction\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction *[top](#Top)*\n",
    "\n",
    "This project is related to Data Wrangling with MongoDB course for Udacity Data Analyst Nanodegree program.\n",
    "The purpose of this project is to clean data from [OpenStreetMap](https://www.openstreetmap.org).\n",
    "\n",
    "OpenStreetMap is open data, licensed under the Open Data Commons Open Database License (ODbL) by the OpenStreetMap Foundation (OSMF). \n",
    "\n",
    "This project cover various aspects of data wrangling phase:\n",
    "- **screen scraping** with [Requests](http://requests.readthedocs.io/en/master/), an http Python library for making requests on web services,\n",
    "- **parsing** XML files with iterative and SAX parsers with Python standard library [xml.etree.ElementTree](https://docs.python.org/2/library/xml.etree.elementtree.html?highlight=iterparse#module-xml.etree.ElementTree) and [xml.sax](https://docs.python.org/2/library/xml.sax.html),\n",
    "- **auditing** (validity, accuracy, completeness, consistency and uniformity) and **cleaning** data with Python,\n",
    "    - validity: does data conform to a schema ?\n",
    "    - accuracy: does data conform to gold standard (a dataset we trust) ?\n",
    "    - completeness: do we have all records ?\n",
    "    - consistency: is dataset providing contradictory information ?\n",
    "    - uniformity: are all data provided in the same units ?\n",
    "- **storing** data into SQL database (SQLite) with Python [sqlite3](https://docs.python.org/2/library/sqlite3.html) module and [MongoDG](https://www.mongodb.com/) no-SQL database.\n",
    "- exploring dataset **statistics** as per project requirements (size of the file, number of unique users, number of nodes and ways, number of chosen type of nodes, like cafes, shops etc.)\n",
    "\n",
    "The storing step will make use of [csv](https://docs.python.org/2/library/csv.html?highlight=csv#module-csv) and [json](https://docs.python.org/2/library/json.html?highlight=json#module-json) formats respectively for SQL and MongoDB exports.\n",
    "\n",
    "I am already familiar with SQL but I will also provide SQL output in addition to MongoDB output for the cleaned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Area selection\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map area selection *[top](#Top)*\n",
    "\n",
    "If you don't want to have details on how the data from OpenStreetMap is retrieved, you can skip this section. At the end of the processing, you should have a *data.osm* file in the same directory than this notebook.\n",
    "\n",
    "I have made the map area selection dynamic. By configuring few variables, a different map area may be extracted from OpenStreetMap. Some pre-selections are available:\n",
    "\n",
    "| Pre-selection | Description               | Usage               | File size (bytes) | OpenStreetMap link |\n",
    "|:------------- |:------------------------- |:------------------- | -----------------:|:------------------ |\n",
    "| Tournefeuille | The city I live in        | Project review      | 103 143 437       | [link](https://www.openstreetmap.org/relation/35735)\n",
    "| City center   | Tournefeuille city center | Testing, debugging  | 583 419           | [link](https://www.openstreetmap.org/export#map=14/43.5848/1.3516)\n",
    "| Toulouse      | Toulouse and surroundings | Benchmark           | 1 271 859 210     | [link](https://www.openstreetmap.org/search?query=toulouse#map=11/43.6047/1.4442)\n",
    "\n",
    "The box variables are in the following order (south-west to north-east):\n",
    "\n",
    "- minimum latitude\n",
    "- minimum longitude\n",
    "- maximum latitude\n",
    "- maximum longitude\n",
    "\n",
    "**Note: ** The data cleaning provided in this project works for French area, if you select a non-french area no data cleaning will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SELECTION = \"PRESELECTED\" #Update the PRESELECTION variable\n",
    "#SELECTION = \"USER\" #Update the USER_SELECTION with the box you want\n",
    "#SELECTION = \"CACHE\" #Use any data file present in directory\n",
    "USER_SELECTION = (43.5799, 1.3434, 43.5838, 1.3496)\n",
    "PRESELECTIONS = {\"Tournefeuille\": (43.5475, 1.2767, 43.6019, 1.3909),\n",
    "                 \"City center\": (43.5799, 1.3434, 43.5838, 1.3496),\n",
    "                 \"Toulouse\": (43.3871, 0.9874, 43.8221, 1.9006)}\n",
    "PRESELECTION = \"Tournefeuille\"\n",
    "TEMPLATE = \\\n",
    "\"\"\"\n",
    "(\n",
    "   node({},{},{},{});\n",
    "   <;\n",
    ");\n",
    "out meta;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used screen scrapping techniques presented throught the course to extract data from OpenStreetMap:\n",
    "\n",
    "- I use the Overpass API (http://wiki.openstreetmap.org/wiki/Overpass_API)\n",
    "- The query form (http://overpass-api.de/query_form.html) sends a POST request to http://overpass-api.de/api/interpreter\n",
    "- From the api/interpreter we can just make a GET request which takes a data parameter containing the box selection:\n",
    "\n",
    "```\n",
    "(\n",
    "   node(51.249,7.148,51.251,7.152);\n",
    "   <;\n",
    ");\n",
    "out meta;\n",
    "```\n",
    "\n",
    "The idea is to send a http GET request using [Requests](http://requests.readthedocs.io/en/master/) and collect results in a stream. This is because the data we get from the request may be huge and may not fit into memory.\n",
    "\n",
    "The following method `download_map_area` enables to download map area data and store it in a *data.osm* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_map_area():\n",
    "    \"\"\"\n",
    "    Download the map area in a file named data.osm.\n",
    "    \n",
    "    This function takes into account the following global variables: SELECTION, USER_SELECTION, PRESELECTIONS, \n",
    "    PRESELECTION and TEMPLATE\n",
    "    \n",
    "    If a http request is made, the response status code is returned, otherwise None in returned.\n",
    "    If SELECTION is set to CACHE and no file is present an exception is raised.\n",
    "    \n",
    "    - raise ValueError: if SELECTION=CACHE and there is no cached file\n",
    "    - raise ValueError: if SELECTION is not [PRESELECTED, USER, CACHE]\n",
    "    - raise NameError if either of SELECTION, PRESELECTION, PRESELECTIONS, USER_SELECTION or TEMPLATE does not exist.\n",
    "    - return: tuple:\n",
    "        - status code or None\n",
    "        - path to dataset\n",
    "        - dataset file size (in bytes)\n",
    "    \"\"\"\n",
    "    filename = \"data.osm\"\n",
    "    if SELECTION == \"CACHE\":\n",
    "        if not os.path.exists(filename):\n",
    "            raise ValueError(\"Cannot use SELECTION=CACHE if no {} file exists.\".format(filename))\n",
    "        else:\n",
    "            return None, filename, os.path.getsize(filename)\n",
    "    elif SELECTION == \"PRESELECTED\":\n",
    "        data = TEMPLATE.format(*PRESELECTIONS[PRESELECTION])\n",
    "    elif SELECTION == \"USER\":\n",
    "        data = TEMPLATE.format(*USER_SELECTION)\n",
    "    else:\n",
    "        raise ValueError(\"SELECTION=\")\n",
    "        \n",
    "    #Get XML data\n",
    "    r = requests.get('http://overpass-api.de/api/interpreter', params={\"data\": data}, stream=True)\n",
    "    with open(filename, 'wb') as fobj:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk:\n",
    "                fobj.write(chunk)\n",
    "    return r.status_code, filename, os.path.getsize(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file data.osm has been successfully downloaded. Its size is 103240060 bytes.\n"
     ]
    }
   ],
   "source": [
    "#Download dataset\n",
    "status_code, dataset_path, dataset_size = download_map_area()\n",
    "if status_code is None:\n",
    "    print \"The file {} is re-used from a previous download. Its size is {} bytes.\".format(dataset_path, dataset_size)\n",
    "elif status_code == 200:\n",
    "    print \"The file {} has been successfully downloaded. Its size is {} bytes.\".format(dataset_path, dataset_size)\n",
    "else:\n",
    "    print \"An error occured while downloading the file. Http status code is {}.\".format(status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"XML data structure\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML data structure *[top](#Top)*\n",
    "\n",
    "In the previous section, we have downloaded a dataset from OpenStreetMap web service. The XML file retrieved this way is stored in the file named *data.osm*.\n",
    "\n",
    "In this section we are going to familiarize with the dataset to understand how it's built. As dataset may be a very large file (depending on the map area extracted) we are going to use an iterative parser that does not need to load the entire document in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the XML library\n",
    "import xml.etree.cElementTree as et\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 17264,\n",
      " 'meta': 1,\n",
      " 'nd': 602009,\n",
      " 'node': 428784,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 469,\n",
      " 'tag': 218904,\n",
      " 'way': 71960}\n"
     ]
    }
   ],
   "source": [
    "#Iterative parsing\n",
    "element_tags = Counter()\n",
    "for (event, elem) in et.iterparse(dataset_path):\n",
    "    element_tags[elem.tag] += 1\n",
    "pprint(dict(element_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In OpenStreetMap, data is structured this way:\n",
    "- A **node** is a location in space defined by its latitude and longitude. It might indicate a standalone point and/or can be used to define shape of a way.\n",
    "- A **way** can be either a polyline to represent roads, rivers... or a closed polygon to delimit areas (buildings, parks...).\n",
    "- A **nd** is used within way to reference nodes.\n",
    "- A **relation** can be defined from **member** nodes and ways to represent routes, bigger area such as regions or city boundaries.\n",
    "- A **member** is a subpart of a relation pointing either to a node or a way.\n",
    "- A **tag** is a (key, value) information attached to nodes, ways and relations to document in more detail the item.\n",
    "- **osm** is the root node in .osm files.\n",
    "- **note** and **meta** are metadata.\n",
    "\n",
    "We are now going to parse the XML file again to get the full path of each tag in the dataset. We need to use a SAX parser with a custom handler. Do not pay attention to callbacks, this will be explained in next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import tempfile\n",
    "import shutil\n",
    "#This library enables to improve performances with big files using disk caching\n",
    "try:\n",
    "    import diskcache\n",
    "except ImportError:\n",
    "    WITH_DISKCACHE = False\n",
    "else:\n",
    "    WITH_DISKCACHE = True\n",
    "\n",
    "\"\"\"\n",
    "Custom handlers for parsing OpenStreetMap XML files.\n",
    "\n",
    "While parsing the XML file, handler keeps trace of:\n",
    "\n",
    "- tags count\n",
    "- tags ancestors\n",
    "\n",
    "It is possible to register callback functions for start or end events.\n",
    "The callbacks for start event will be called passing the following arguments:\n",
    "- element name, \n",
    "- element attributes,\n",
    "- locator,\n",
    "- ancestor\n",
    "\n",
    "The callbacks for end event will be called passing the following arguments:\n",
    "- element name \n",
    "- locator,\n",
    "- element children\n",
    "\n",
    "Return value of callbacks is ignored by the handler class.\n",
    "\n",
    "This enables to enhance the parser with 'on the fly' data quality audit.\n",
    "\"\"\"\n",
    "class OpenStreetMapXmlHandler(xml.sax.ContentHandler):\n",
    "    def __init__(self, caching=False):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        The state of object keeps a trace of stack while parsing. This enables to collect information \n",
    "        from children. The stack is destroyed when end event occured. This enables to limit memory usage\n",
    "        while parsing.\n",
    "        \n",
    "        The _stack internal variable stores tuples\n",
    "        - element unique identifier\n",
    "        - element name (as provided by start event)\n",
    "        - element attributes (as provided by start event)\n",
    "        \"\"\"\n",
    "        xml.sax.ContentHandler.__init__(self)      #super not working here ???\n",
    "        self._caching = caching\n",
    "        \n",
    "    def __enter__(self):\n",
    "        \"\"\"\n",
    "        Context manager entry point.\n",
    "        \"\"\"\n",
    "        self._id = 0                               #unique identifier incremented at\n",
    "        self._stack = [ ]                          #current stack of element being read\n",
    "        self._element_tags = Counter()             #counter of element tags\n",
    "        self._element_ancestors = defaultdict(set) #collection of ancestors per tag\n",
    "        self._start_callbacks = [ ]                #start event callbacks\n",
    "        self._end_callbacks = [ ]                  #end event callbacks\n",
    "        #Disk caching ?\n",
    "        if self._caching and WITH_DISKCACHE:\n",
    "            self._tmpdir = tempfile.mkdtemp()\n",
    "            self._children = diskcache.Cache(self._tmpdir)\n",
    "        else:\n",
    "            self._children = { }                   #children elements of elements being read\n",
    "        return self\n",
    "            \n",
    "    def __exit__(self, *args):\n",
    "        \"\"\"\n",
    "        Context manager exit point.\n",
    "        \n",
    "        Clean up temporary directories and cache.\n",
    "        \"\"\"\n",
    "        if self._caching and WITH_DISKCACHE:\n",
    "            self._children.close()\n",
    "            shutil.rmtree(self._tmpdir)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        \"\"\"\n",
    "        Method invoked when starting to read an element in XML dataset.\n",
    "\n",
    "        This method is part of of xml.sax.ContentHandler interface and is overloaded here.\n",
    "\n",
    "        - name: tag of element being read\n",
    "        - attrs: element attributes\n",
    "        \"\"\"\n",
    "        #Get identifier for current element\n",
    "        identifier = self._requestUniqueIdentifier()\n",
    "\n",
    "        #Has element a parent? If yes get the id.\n",
    "        try:\n",
    "            parent = self._stack[-1][0]\n",
    "        except IndexError:\n",
    "            parent = None\n",
    "                    \n",
    "        #Exploit current stack to get ancestor\n",
    "        ancestor = \".\".join([s[1] for s in self._stack])\n",
    "        self._element_ancestors[name].add(ancestor)\n",
    "        \n",
    "        #Update tag counter\n",
    "        self._element_tags[name] += 1\n",
    "        \n",
    "        #Update parent children (if any)\n",
    "        if parent is not None:\n",
    "            self._children[parent].append((name, attrs))\n",
    "            \n",
    "        #Initialisation of own children\n",
    "        self._children[identifier] = [ ]\n",
    "        \n",
    "        #Update stack\n",
    "        self._stack.append((identifier, name, attrs))\n",
    "        \n",
    "        #Use registered callbacks\n",
    "        for callback in self._start_callbacks:\n",
    "            callback(name, attrs, self._locator, ancestor)\n",
    "        \n",
    "    def endElement(self, name):\n",
    "        \"\"\"\n",
    "        Method invoked when ending to read an element in XML dataset.\n",
    "\n",
    "        This method is part of of xml.sax.ContentHandler interface and is overloaded here.\n",
    "\n",
    "        - name: tag of element being read\n",
    "        \"\"\"        \n",
    "        #Get identifier\n",
    "        identifier = self._stack[-1][0]\n",
    "        \n",
    "        #Use registered callbacks before element is cleaned        \n",
    "        for callback in self._end_callbacks:\n",
    "            callback(name, self._locator, self._children[identifier])\n",
    "            \n",
    "        #Cleaning\n",
    "        identifier, name, attrs = self._stack.pop(-1)\n",
    "        del self._children[identifier]\n",
    "            \n",
    "    def getTagsCount(self):\n",
    "        \"\"\"\n",
    "        Get a dictionnary with tags count.\n",
    "\n",
    "        - return: dictionnary where keys are tags and values are count\n",
    "        \"\"\"\n",
    "        return dict(self._element_tags)\n",
    "\n",
    "    def getTagsAncestors(self):\n",
    "        \"\"\"\n",
    "        Get a dictionnary with tags ancestors.\n",
    "\n",
    "        - return: dictionnary where keys are tags and values are a sequence of all different ancestors path\n",
    "        \"\"\"\n",
    "        return dict(self._element_ancestors)\n",
    "    \n",
    "    def registerStartEventCallback(self, func):\n",
    "        \"\"\"\n",
    "        Register a callback for start event.\n",
    "\n",
    "        Note that return value of callback is ignored. Any exception raised by callback is not catched by handler, \n",
    "        so you should take care of catching all exceptions within the callback itself.\n",
    "\n",
    "        - func: a callable object taking element name, element attributes, locator and ancestor as arguments.\n",
    "        \"\"\"\n",
    "        self._start_callbacks.append(func)\n",
    "        \n",
    "    def registerEndEventCallback(self, func):\n",
    "        \"\"\"\n",
    "        Register a callback for end event.\n",
    "\n",
    "        Note that return value of callback is ignored. Any exception raised by callback is not catched by handler, \n",
    "        so you should take care of catching all exceptions within the callback itself.\n",
    "\n",
    "        - func: a callable object taking element name, locator and element children as arguments.\n",
    "        \"\"\"\n",
    "        self._end_callbacks.append(func)\n",
    "        \n",
    "    def clearCallbacks(self):\n",
    "        \"\"\"\n",
    "        Remove all registered callbacks.\n",
    "        \"\"\"\n",
    "        self._end_callbacks = [ ]\n",
    "        self._start_callbacks = [ ]\n",
    "        \n",
    "    def _requestUniqueIdentifier(self):\n",
    "        \"\"\"\n",
    "        Return a unique identifier used at parsing time.\n",
    "        \n",
    "        - return: identifier\n",
    "        \"\"\"\n",
    "        self._id += 1\n",
    "        return self._id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the handler in SAX parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = xml.sax.make_parser()\n",
    "with OpenStreetMapXmlHandler(caching=False) as handler:\n",
    "    parser.setContentHandler(handler)\n",
    "    parser.parse(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'member': 17264,\n",
      " u'meta': 1,\n",
      " u'nd': 602009,\n",
      " u'node': 428784,\n",
      " u'note': 1,\n",
      " u'osm': 1,\n",
      " u'relation': 469,\n",
      " u'tag': 218904,\n",
      " u'way': 71960}\n"
     ]
    }
   ],
   "source": [
    "#Get tag counts\n",
    "pprint(handler.getTagsCount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned tag count is the same than the one we have calculated using `et.iterparse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'member': set([u'osm.relation']),\n",
      " u'meta': set([u'osm']),\n",
      " u'nd': set([u'osm.way']),\n",
      " u'node': set([u'osm']),\n",
      " u'note': set([u'osm']),\n",
      " u'osm': set(['']),\n",
      " u'relation': set([u'osm']),\n",
      " u'tag': set([u'osm.node', u'osm.relation', u'osm.way']),\n",
      " u'way': set([u'osm'])}\n"
     ]
    }
   ],
   "source": [
    "#Get tag ancestors\n",
    "pprint(handler.getTagsAncestors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed later on:\n",
    "- **osm** element has no ancestor (it's root element)\n",
    "- **meta** and **note** only appear in **osm** element\n",
    "- **node**, **way** and **relation** are direct children of **osm**\n",
    "- **tag** can be used to document any of **node**, **way** and **relation**\n",
    "- **member** are only used in **relation** elements (to reference either nodes, ways or other relations)\n",
    "- **nd** are only used in **way** elements (to reference nodes)\n",
    "\n",
    "Such result will help us a lot when auditing [data quality](#Data quality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data quality'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality audit *[top](#Top)*\n",
    "\n",
    "This chapter is divided into 5 sections for each kind of data quality audit:\n",
    "- [Validity](#Data validity)\n",
    "- [Accuracy](#Data accuracy)\n",
    "- [Completeness](#Data completeness)\n",
    "- [Consistency](#Data consistency)\n",
    "- [Uniformity](#Data uniformity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data validity'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity *[audit](#Data quality)*\n",
    "\n",
    "Validity is about compliance to a schema. The data we have retrieved from OpenStreetMap servers is a XML file. It exists techniques to validate XML structures such as XML Schema. We won't use such technique here because schema is relatively simple and because XML files can be large enough so we want to stick to using SAX parser.\n",
    "\n",
    "Actually, the SAX content handler that has been introduced in previous [section](#XML data structure) will be helpful here as it's already able to list ancestors for each element. We can then define a schema in a similar form and compare both to see if there is any issue.\n",
    "\n",
    "The schema is a dictionnary structured this way:\n",
    "- key: element tag\n",
    "- value: dictionnary with the following keys / values:\n",
    "    - *ancestors*: List of any acceptable ancestor path. For example, the path ('osm.way') means that element shall be a children of a way element which itself is a children of a osm element.\n",
    "    - *minOccurences*: minimum number of element in the dataset (greater or equal to 0), optional\n",
    "    - *maxOccurences*: maximum number of element in the dataset (greater or equal to 1), optional\n",
    "    - *requiredAttributes*: list of attribute names that shall be defined for element\n",
    "    - *requiredChildren*: list of required children element\n",
    "    - *attributesFuncs*: list of callable objects to be run on the element attributes for further checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "#Function to check numbers\n",
    "check_digit = lambda name, attr: attr[name].isdigit()\n",
    "check_id_digit = functools.partial(check_digit, 'id')\n",
    "check_ref_digit = functools.partial(check_digit, 'ref')\n",
    "\n",
    "#Define a schema\n",
    "schema = {\n",
    "    #osm is root node. There shall be exactely one.\n",
    "    'osm': { \n",
    "        'ancestors': {''}, \n",
    "        'minOccurences': 1,\n",
    "        'maxOccurences': 1},\n",
    "    #meta shall be within osm element. There shall be exactely one of those.\n",
    "    'meta': {\n",
    "        'ancestors': {'osm'},\n",
    "        'minOccurences': 1,\n",
    "        'maxOccurences': 1},\n",
    "    #meta shall be within osm element. There shall be exactely one of those.\n",
    "    'note': {\n",
    "        'ancestors': {'osm'},\n",
    "        'minOccurences': 1,\n",
    "        'maxOccurences': 1},        \n",
    "    #node shall be within osm element. A node shall have id, lat (latitude) and lon (longitude) attributes.\n",
    "    #Additionally, lat shall be in the range [-90, 90] and longitude in the range [-180, 180]. Id shall be a digit \n",
    "    #number\n",
    "    'node': {\n",
    "        'ancestors': {'osm'},\n",
    "        'requiredAttributes': ['id', 'lat', 'lon'],\n",
    "        'attributesFuncs': [lambda attr: -90 <= float(attr['lat']) <= 90, \n",
    "                            lambda attr: -180 <= float(attr['lon']) <= 180,\n",
    "                            check_id_digit]},\n",
    "    #way shall be within osm element. A way shall have id attribute. It shall have at least one nd children.\n",
    "    #id shall be a digit.\n",
    "    'way': {\n",
    "        'ancestors': {'osm'},\n",
    "        'requiredAttributes': ['id'],\n",
    "        'requiredChildren': ['nd'],\n",
    "        'attributesFuncs': [check_id_digit]},\n",
    "    #nd shall be within way element. A nd shall have ref attribute. ref attribute shall be a digit.\n",
    "    'nd': {\n",
    "        'ancestors': {'osm.way'},\n",
    "        'requiredAttributes': ['ref'],\n",
    "        'attributesFuncs': [check_ref_digit]},\n",
    "    #relation shall be within a osm element. It shall have a id attribute and at least one member children. id shall\n",
    "    #be a digit\n",
    "    'relation': {\n",
    "        'ancestors': {'osm'},\n",
    "        'requiredAttributes': ['id'],\n",
    "        'requiredChildren': ['member'],\n",
    "        'attributesFunc': [check_id_digit]},\n",
    "    #member shall be within a relation element. It shall have type, ref and role attributes. The type attribute shall\n",
    "    #be either way or node. The ref attribute shall be a digit.\n",
    "    'member': {\n",
    "        'ancestors': {'osm.relation'},\n",
    "        'requiredAttributes': ['type', 'ref', 'role'],\n",
    "        'attributesFuncs': [lambda attr: attr['type'] in ['way', 'node', 'relation'],\n",
    "                            check_ref_digit]},\n",
    "        \n",
    "    #tag shall be within node, way or relation. It shall have k and v attributes.\n",
    "    'tag': {\n",
    "        'ancestors': {'osm.node', 'osm.way', 'osm.relation'},\n",
    "        'requiredAttributes': ['k', 'v']},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have this schema validated, we are going to create a callback to be passed to SAX content handler we have created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data validity audit object in a form of a callback for SAX content handler.\n",
    "\n",
    "This audit class checks the validity to a schema. The nonconformities can be requested after parsing.\n",
    "\"\"\"\n",
    "class DataValidityAudit(object):\n",
    "    \"\"\"\n",
    "    Constructor.\n",
    "    \n",
    "    The specified schema has the following structure:\n",
    "    \n",
    "    - key: element tag\n",
    "    - value: dictionnary with the following keys / values:\n",
    "        - *ancestors*: List of any acceptable ancestor path. For example, the path 'osm.way' means that element \n",
    "        shall be a children of a way element which itself is a children of a osm element.\n",
    "        - *minOccurences*: minimum number of element in the dataset (greater or equal to 0), optional\n",
    "        - *maxOccurences*: maximum number of element in the dataset (greater or equal to 1), optional\n",
    "        - *requiredAttributes*: list of attribute names that shall be defined for element\n",
    "        - *requiredChildren*: list of required children element\n",
    "        - *attributesFuncs*: list of callable objects to be run on the element attributes for further checks\n",
    "    \n",
    "    - schema: dictionnary with schema to be checked.\n",
    "    \"\"\"\n",
    "    def __init__(self, schema):\n",
    "        self._schema = schema\n",
    "        self._count_tags = Counter()\n",
    "        self._nonconformities = [ ]\n",
    "    \n",
    "    \"\"\"\n",
    "    Method called back when a start event is encountered.\n",
    "    \n",
    "    - name: element name\n",
    "    - attrs: element attributes\n",
    "    - locator: locator object from SAX parser\n",
    "    - ancestor: ancestor in the form of a string\n",
    "    \"\"\"\n",
    "    def startEventCallback(self, name, attrs, locator, ancestor):\n",
    "        #Update counter\n",
    "        self._count_tags[name] += 1\n",
    "        \n",
    "        #Check ancestors\n",
    "        try:\n",
    "            ancestors = self._schema[name]['ancestors']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            if ancestor not in ancestors:\n",
    "                message = \"{} element at line {} and column {} has an invalid ancestor: {}\".format(\n",
    "                    name, locator.getLineNumber(), locator.getColumnNumber(), ancestor)\n",
    "                self._nonconformities.append(('Validity', message))\n",
    "                \n",
    "        #Check attributes\n",
    "        try:\n",
    "            required_attributes = self._schema[name]['requiredAttributes']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            for attribute in required_attributes:\n",
    "                try:\n",
    "                    attrs[attribute]\n",
    "                except KeyError:\n",
    "                    message = \"{} element at line {} and column {} is missing a required attribute {}.\".format(\n",
    "                        name, locator.getLineNumber(), locator.getColumnNumber(), attribute)\n",
    "                    self._nonconformities.append(('Validity', message))\n",
    "                    \n",
    "        #Special checks for attributes\n",
    "        try:\n",
    "            funcs = self._schema[name]['attributesFuncs']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            for i, func in enumerate(funcs):\n",
    "                try:\n",
    "                    status = func(attrs)\n",
    "                except Exception as e:\n",
    "                    exception = \"{}({})\".format(type(e).__name__, e)\n",
    "                    message = \"An exception {} has been raised while checking attributes with function {} \" \\\n",
    "                            \"for element {} at line {} and column {}.\".format(\n",
    "                            exception, i, name, locator.getLineNumber(), locator.getColumnNumber())\n",
    "                    self._nonconformities.append(('Validity', message))\n",
    "                else:\n",
    "                    if not status:\n",
    "                        message = \"A custom attribute check failed with function {} for element {} at line {} \" \\\n",
    "                            \"and column {}.\".format(i, name, locator.getLineNumber(), locator.getColumnNumber())\n",
    "                        self._nonconformities.append(('Validity', message))\n",
    "                        \n",
    "    \"\"\"\n",
    "    Method called back when an end event is encountered.\n",
    "    \n",
    "    - name: element name\n",
    "    - locator: locator object from SAX parser\n",
    "    - children: element children\n",
    "    \"\"\"\n",
    "    def endEventCallback(self, name, locator, children):\n",
    "        #Check required children\n",
    "        try:\n",
    "            required_children = self._schema[name]['requiredChildren']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            actual_children = {c[0] for c in children}\n",
    "            for r in required_children:\n",
    "                if r not in actual_children:\n",
    "                    message = \"An element {} is missing in element {} at line {} and column {}.\".format(\n",
    "                            r, name, locator.getLineNumber(), locator.getColumnNumber())\n",
    "                    self._nonconformities.append(('Validity', message))\n",
    "\n",
    "    \"\"\"\n",
    "    Return nonconformities.\n",
    "    \n",
    "    A list of tuple is returned:\n",
    "    - type of audit\n",
    "    - nonconformity description\n",
    "    \"\"\"\n",
    "    def getNonconformities(self):\n",
    "        #Initialization\n",
    "        nonconformities = self._nonconformities[:]\n",
    "        \n",
    "        #Check occurences (we cannot do that on the fly)\n",
    "        for tag, conf in self._schema.iteritems():\n",
    "            try:\n",
    "                min_occurs = conf['minOccurences']\n",
    "            except KeyError:\n",
    "                pass\n",
    "            else:\n",
    "                if self._count_tags[tag] < min_occurs:\n",
    "                    message = \"The minOccurences criteria failed for {} element. \" \\\n",
    "                        \"Found {} element(s) while {} is the minimum.\".format(tag, self._count_tags[tag], min_occurs)\n",
    "                    nonconformities.append(('Validity', message))\n",
    "            try:\n",
    "                max_occurs = conf['maxOccurences']\n",
    "            except KeyError:\n",
    "                pass\n",
    "            else:\n",
    "                if self._count_tags[tag] > max_occurs:\n",
    "                    message = \"The maxOccurences criteria failed for {} element. \" \\\n",
    "                        \"Found {} element(s) while {} is the maximum.\".format(tag, self._count_tags[tag], max_occurs)\n",
    "                    nonconformities.append(('Validity', message))\n",
    "            \n",
    "        #End of post-processing\n",
    "        return nonconformities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabulate\n",
    "\n",
    "#Define a method to parse and audit\n",
    "def parse_and_audit(dataset_path, audit=None):\n",
    "    \"\"\"\n",
    "    Parse XML dataset and perform audit quality.\n",
    "    \n",
    "    - dataset_path: path to the dataset to be parsed and audited\n",
    "    - audit: a sequence of audit objects\n",
    "    - return: sequence of nonconformities\n",
    "    \"\"\"\n",
    "    with OpenStreetMapXmlHandler() as handler:\n",
    "        if audit is not None:\n",
    "            for obj in audit:\n",
    "                handler.registerStartEventCallback(obj.startEventCallback)\n",
    "                handler.registerEndEventCallback(obj.endEventCallback)\n",
    "        parser = xml.sax.make_parser()\n",
    "        parser.setContentHandler(handler)\n",
    "        parser.parse(dataset_path)\n",
    "    nonconformities = []\n",
    "    if audit is not None:\n",
    "        for obj in audit:\n",
    "            nonconformities.extend(obj.getNonconformities())\n",
    "    return nonconformities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 148 ms, total: 13.2 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Parse and audit\n",
    "%time nonconformities = parse_and_audit(dataset_path, [DataValidityAudit(schema)])\n",
    "display(HTML(tabulate.tabulate(nonconformities, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned list above shall be empty. It means that no nonconfirmity has been detected for validity audit. The data we get from OpenStreetMap may be trusted in terms of schema compliance.\n",
    "\n",
    "The `%%timeit` Jupyter magic command enables to monitor how much time it takes to parse and audit the data. As a reference it takes approximately 12 seconds to parse and audit the dataset of around 100 Mb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data accuracy'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy *[audit](#Data quality)*\n",
    "\n",
    "Accuracy is a measurement of coformity with gold standard. On a dataset such as the one from OpenStreetMap it may be difficult to find a gold standard. We are then going to limit this audit to values that are sometimes provided in the dataset for items which represents a town:\n",
    "- INSEE indentifier (ref:INSEE in the above example)\n",
    "- Population\n",
    "- Date of last census (source:population in the above example)\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "```xml\n",
    "<node id=\"26691412\" lat=\"43.5827846\" lon=\"1.3466543\" version=\"16\" timestamp=\"2017-08-21T22:29:38Z\"  changeset=\"51321527\" uid=\"6523296\" user=\"ccampguilhem\">\n",
    "    <tag k=\"addr:postcode\" v=\"31170\"/>\n",
    "    <tag k=\"name\" v=\"Tournefeuille\"/>\n",
    "    <tag k=\"name:fr\" v=\"Tournefeuille\"/>\n",
    "    <tag k=\"name:oc\" v=\"Tornafuèlha\"/>\n",
    "    <tag k=\"place\" v=\"town\"/>\n",
    "    <tag k=\"population\" v=\"26 674\"/>\n",
    "    <tag k=\"ref:FR:SIREN\" v=\"213105570\"/>\n",
    "    <tag k=\"ref:INSEE\" v=\"31557\"/>\n",
    "    <tag k=\"source:population\" v=\"INSEE 2014\"/>\n",
    "    <tag k=\"wikidata\" v=\"Q328022\"/>\n",
    "    <tag k=\"wikipedia\" v=\"fr:Tournefeuille\"/>\n",
    "</node>\n",
    "```\n",
    "\n",
    "For this example, I have updated the OpenStreetMap database manually to match official data published by [INSEE](https://www.insee.fr/en/accueil). I will use INSEE data as gold standard (see [here](https://www.insee.fr/fr/statistiques/1405599?geo=COM-31557+COM-31291+COM-31149+COM-31424+COM-31157+COM-31417)). The last census in my region is from 2014.\n",
    "\n",
    "We are going to define a gold standard in a dictionnary for few towns in the surrounding of Tournefeuille. If you have selected a user-defined area map, it may not be suitable to you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to convert digit in XML with thoudand separators into a Python integer\n",
    "convert_to_int = lambda x: int(x.replace(\" \", \"\"))\n",
    "\n",
    "gold_standard = {\n",
    "    u'Tournefeuille': {\n",
    "        'population': (convert_to_int, 26674),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31557)},\n",
    "    u'Léguevin': {\n",
    "        'population': (convert_to_int, 8892),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31291)},\n",
    "    u'Colomiers': {\n",
    "        'population': (convert_to_int, 38541),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31149)},\n",
    "    u'Plaisance-du-Touch': {\n",
    "        'population': (convert_to_int, 17278),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31424)},\n",
    "    u'Cugnaux': {\n",
    "        'population': (convert_to_int, 17004),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31157)},\n",
    "    u'Pibrac': {\n",
    "        'population': (convert_to_int, 8226),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31417)},\n",
    "    u'Toulouse': {\n",
    "        'population': (convert_to_int, 466297),\n",
    "        'source:population': (str, 'INSEE 2014'),\n",
    "        'ref:INSEE': (convert_to_int, 31555)},       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an audit class for accuracy. It will compare each information from items having a \"population\" tag to the standard above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data accuracy audit object in a form of a callback for SAX content handler.\n",
    "\n",
    "This audit class checks compliance to gold standard. The nonconformities can be requested after parsing.\n",
    "This audit is only applied to elements which has a tag element child with k = population.\n",
    "\"\"\"\n",
    "class DataAccuracyAudit(object):\n",
    "    \"\"\"\n",
    "    Constructor.\n",
    "    \n",
    "    The specified standard has the following structure:\n",
    "    \n",
    "    - key: town name\n",
    "    - value: dictionnary with the following keys / values. Each value is a tuple of conversion function and expected \n",
    "    value:\n",
    "        - *population*: population as measured during the last census\n",
    "        - *source:population*: source of last census\n",
    "        - *ref:INSEE*: identifier of town in gold standard (INSEE)\n",
    "        \n",
    "    - standard: gold standard dictionnary\n",
    "    - fix: toggle automatic fixing of data\n",
    "    \"\"\"\n",
    "    def __init__(self, standard, fix=False):\n",
    "        self._standard = standard\n",
    "        self._nonconformities = [ ]\n",
    "        self._fix = fix\n",
    "    \n",
    "    \"\"\"\n",
    "    Method called back when a start event is encountered.\n",
    "    \n",
    "    - name: element name\n",
    "    - attrs: element attributes\n",
    "    - locator: locator object from SAX parser\n",
    "    - ancestor: ancestor in the form of a string\n",
    "    \"\"\"\n",
    "    def startEventCallback(self, name, attrs, locator, ancestor):\n",
    "        pass\n",
    "                                \n",
    "    \"\"\"\n",
    "    Method called back when an end event is encountered.\n",
    "    \n",
    "    - name: element name\n",
    "    - locator: locator object from SAX parser\n",
    "    - children: element children\n",
    "    \"\"\"\n",
    "    def endEventCallback(self, name, locator, children):\n",
    "        #Find item with a tag child haing population as k value and compare to standard\n",
    "        match = self._findTagInChildren(children, 'population')\n",
    "        if match is not None:\n",
    "            town = self._findTagInChildren(children, 'name:fr')\n",
    "            try:\n",
    "                standard = self._standard[town]\n",
    "            except KeyError:\n",
    "                message = \"Town {} has been found and not in standard. Accuracy cannot be assessed.\".format(town)\n",
    "                self._nonconformities.append(('Accuracy', message))\n",
    "            else:\n",
    "                for key, value in standard.iteritems():\n",
    "                    dataset_value = value[0](self._findTagInChildren(children, key))\n",
    "                    if dataset_value != value[1]:\n",
    "                        message = '\"{}\" value provided for \"{}\" of town {} is inaccurate. '\\\n",
    "                                'Expected value is \"{}\".'.format(dataset_value, key, town, value[1])\n",
    "                        self._nonconformities.append(('Accuracy', message))\n",
    "        \n",
    "    \"\"\"\n",
    "    Return nonconformities.\n",
    "    \n",
    "    A list of tuple is returned:\n",
    "    - type of audit\n",
    "    - nonconformity description\n",
    "    \"\"\"\n",
    "    def getNonconformities(self):\n",
    "        return self._nonconformities[:]\n",
    "    \n",
    "    def _findTagInChildren(self, children, key, value=None):\n",
    "        \"\"\"\n",
    "        Find in children a tag element with specified attribute key.\n",
    "        \n",
    "        If value is set to None, the value is returned. If value is specified, name et attrs of child are returned.\n",
    "        In case no element or value is found, None is returned\n",
    "        \n",
    "        - children: list of tuples (name of element, element attributes)\n",
    "        - return: value, (name, attibutes) or None\n",
    "        \"\"\"\n",
    "        #try to get tag with k = place\n",
    "        for name, attrs in children:\n",
    "            #Skip if this is not a tag\n",
    "            if name != \"tag\":\n",
    "                continue\n",
    "            #It's a tag\n",
    "            try:\n",
    "                k = attrs['k']\n",
    "            except KeyError:\n",
    "                continue\n",
    "            else:\n",
    "                if k != key:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        v = attrs['v']\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if value is None:\n",
    "                            return v\n",
    "                        elif v == value:\n",
    "                            return name, attrs\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 192 ms, total: 14.2 s\n",
      "Wall time: 14.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><td>Accuracy</td><td>\"INSEE 2013\" value provided for \"source:population\" of town Plaisance-du-Touch is inaccurate. Expected value is \"INSEE 2014\".</td></tr>\n",
       "<tr><td>Accuracy</td><td>\"16091\" value provided for \"population\" of town Plaisance-du-Touch is inaccurate. Expected value is \"17278\".                 </td></tr>\n",
       "<tr><td>Accuracy</td><td>\"INSEE 2013\" value provided for \"source:population\" of town Colomiers is inaccurate. Expected value is \"INSEE 2014\".         </td></tr>\n",
       "<tr><td>Accuracy</td><td>\"35186\" value provided for \"population\" of town Colomiers is inaccurate. Expected value is \"38541\".                          </td></tr>\n",
       "<tr><td>Accuracy</td><td>\"INSEE 2013\" value provided for \"source:population\" of town Toulouse is inaccurate. Expected value is \"INSEE 2014\".          </td></tr>\n",
       "<tr><td>Accuracy</td><td>\"441802\" value provided for \"population\" of town Toulouse is inaccurate. Expected value is \"466297\".                         </td></tr>\n",
       "<tr><td>Accuracy</td><td>\"INSEE 2013\" value provided for \"source:population\" of town Pibrac is inaccurate. Expected value is \"INSEE 2014\".            </td></tr>\n",
       "<tr><td>Accuracy</td><td>\"8091\" value provided for \"population\" of town Pibrac is inaccurate. Expected value is \"8226\".                               </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Parse and audit\n",
    "%time nonconformities = parse_and_audit(dataset_path, [DataValidityAudit(schema), DataAccuracyAudit(gold_standard)])\n",
    "display(HTML(tabulate.tabulate(nonconformities, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some accuracy issues are reported because data in OpenStreetMap is not up to date since the new census of 2014.\n",
    "No issue is reported for Tournefeuille because I have manually updated the OpenStreetMap database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data completeness'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness *[audit](#Data quality)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data consistency'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency *[audit](#Data quality)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data uniformity'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniformity *[audit](#Data quality)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Appendix\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix *[top](#Top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[OpenStreetData wiki](http://wiki.openstreetmap.org/wiki/Main_Page)<hr>\n",
    "[INSEE](https://www.insee.fr/en/accueil) is French National Institute of Statistics and Economic Information. In this project, it is used as *gold* standard.<hr>\n",
    "Validating XML tree with [XML Schema](https://www.w3schools.com/xml/schema_intro.asp) can be done with [lxml](http://lxml.de/validation.html) library. This technique has not been used here as the structure of XML is simple enough. Additionaly, XML Schema validation requires to have XML data into memory and may not be suitable for large files like the ones we might have here.<hr>\n",
    "Get line number in a content handler with SAX parser on [StackOverflow](https://stackoverflow.com/a/15477803/8500344)<hr>\n",
    "Display lists as html tables in notebook on [StackOverflow](https://stackoverflow.com/a/42323522/8500344)<hr>\n",
    "[Diskcache](http://www.grantjenks.com/docs/diskcache/tutorial.html), a disk and file backed cache library<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataAnalysis]",
   "language": "python",
   "name": "conda-env-DataAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
